{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа № 2 \n",
    "## Машинное обучение на больших данных с использованием фреймворка Apache Spark и библиотеки SparkML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 1\n",
    "\n",
    "В данной части работы рассмотрены:\n",
    "* подготовка признаков для рашения задачи **линейной регрессии**;\n",
    "* создание и обучение модели линейной регрессии;\n",
    "* оценка качества модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запуск `Spark`-сессии\n",
    "\n",
    "Подключаем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, OneHotEncoder, MinMaxScaler, Binarizer\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark.sql.types import DoubleType\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем объект конфигурации для `Apache Spark`, указав необходимые параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_configuration() -> SparkConf:\n",
    "    \"\"\"\n",
    "    Создает и конфигурирует экземпляр SparkConf для приложения Spark.\n",
    "\n",
    "    Returns:\n",
    "        SparkConf: Настроенный экземпляр SparkConf.\n",
    "    \"\"\"\n",
    "    # Получаем имя пользователя\n",
    "    user_name = os.getenv(\"USER\")\n",
    "    \n",
    "    conf = SparkConf()\n",
    "    conf.setAppName(\"lab 2 Test\")\n",
    "    conf.setMaster(\"yarn\")\n",
    "    conf.set(\"spark.submit.deployMode\", \"client\")\n",
    "    conf.set(\"spark.executor.memory\", \"12g\")\n",
    "    conf.set(\"spark.executor.cores\", \"8\")\n",
    "    conf.set(\"spark.executor.instances\", \"2\")\n",
    "    conf.set(\"spark.driver.memory\", \"4g\")\n",
    "    conf.set(\"spark.driver.cores\", \"2\")\n",
    "    conf.set(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.0\")\n",
    "    conf.set(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.type\", \"hadoop\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.warehouse\", f\"hdfs:///user/{user_name}/warehouse\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.io-impl\", \"org.apache.iceberg.hadoop.HadoopFileIO\")\n",
    "\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём сам объект конфигурации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = create_spark_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём и выводим на экран сессию `Apache Spark`. В процессе создания сессии происходит подключение к кластеру `Apache Hadoop`, что может занять некоторое время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка датасета\n",
    "\n",
    "Укажем базу данных, которая была создана в первой лабораторной работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = \"ivanov_database\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим созданную базу данных как текущую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(database_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем таблицу с **предобработанным датасетом** и загрузим её в `Spark Dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.table(\"sobd_lab1_processed_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем прочитанную таблицу на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним описание столбцов и параметры датасета, проанализированные в первой лабораторной работе.\n",
    "\n",
    "| Название столбца          | Расшифровка |  Тип признака и его характеристики\n",
    "| ------------------------- | ------------- | ------------------ |\n",
    "| vin                       | Идентификационный номер автомобиля | категориальный, уникальный |\n",
    "| body_type                 | Тип кузова автомобиля (кабриолет, хэтчбек, седан и т.д.)  | категориальный, 10 категорий (одна неизвестная: NULL) |\n",
    "| daysonmarket              | Количество дней, прошедших с момента первого размещения автомобиля на сайте | количественный, непрерывный, интервал значений [0, 500] |\n",
    "| horsepower                | Мощность двигателя в лошадиных силах | количественный, непрерывный, интервал значений [0, 400] |\n",
    "| maximum_seating           | Максимальное количество посадочных мест | количественный, дискретный, интервал значений [2, 15] |\n",
    "| mileage                   | Величина пробега автомобиля | количественный, непрерывный, интервал значений [0, 200000], большинство значений < 100 |\n",
    "| price                     | Цена автомобиля | количественный, непрерывный, интервал значений [0, 60000] |\n",
    "| wheel_system              | Тип привода | категориальный, 5 категорий |\n",
    "| is_any_cert               | Является ли автомобиль сертифицированным (любым способом) | бинарный, true << false |\n",
    "| contains_Alloy Wheels     | Имеются ли в автомобиле легкосплавные диски | бинарный |\n",
    "| contains_Backup Camera    | Имеется ли в автомобиле резервная камера | бинарный |\n",
    "| contains_Bluetooth        | Имеется ли в автомобиле поддержка Bluetooth | бинарный |\n",
    "| contains_Heated Seats     | Имеется ли в автомобиле подогрев сидений | бинарный |\n",
    "| contains_Sunroof/Moonroof | Имеется ли в автомобиле люк | бинарный |\n",
    "| age                       | Количество лет, прошедших с года выпуска автомобиля до 2024 года | количественный, непрерывный, интервал значений [3, 43] |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним схему данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим количество строк в датафрейме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Постановка задачи линейной регрессии\n",
    "\n",
    "Для датасета, заданного представленными колонками, требуется построить модель линейной регрессии для оценки **стоимости автомобиля** по всем остальным признакам. \n",
    "\n",
    "Для оценки качества обучения следует использовать метрики $RMSE$ и $R^2$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка и кодирование признаков\n",
    "\n",
    "Для корректной работы трансформеров преобразуем столбец `mileage` к типу `DoubleType`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"mileage\", col(\"mileage\").cast(DoubleType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отделим от датасета некоторую часть объёмом примерно 1000 строк, и сохраним её на диске как локальный `csv`-файл. Он понадобится в следующей лабораторной работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_sample_to_csv(data: DataFrame, file_path: str, \n",
    "                       sample_size: int = 1000) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Сохраняет первые `sample_size` строк из DataFrame в CSV-файл \n",
    "    на драйвере и возвращает DataFrame с оставшимися данными.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): DataFrame, из которого нужно извлечь\n",
    "            строки.\n",
    "        file_path (str): Путь для сохранения CSV-файла.\n",
    "        sample_size (int): Количество строк для сохранения\n",
    "            (по умолчанию 1000).\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame с оставшимися данными.\n",
    "    \"\"\"\n",
    "    # Определяем пропорции для разделения\n",
    "    sample_fraction = sample_size / data.count()\n",
    "    remaining_fraction = 1 - sample_fraction\n",
    "\n",
    "    # Разделяем DataFrame на два непересекающихся набора данных\n",
    "    sample_data, remaining_data = data.randomSplit(\n",
    "        [sample_fraction, remaining_fraction]\n",
    "    )\n",
    "\n",
    "    # Сохраняем извлеченные строки в CSV-файл на драйвере\n",
    "    try:\n",
    "        with open(file_path, mode=\"w\", newline=\"\") as file:\n",
    "            writer = csv.writer(file)\n",
    "\n",
    "            # Записываем заголовок\n",
    "            writer.writerow(data.columns)\n",
    "\n",
    "            # Записываем строки\n",
    "            for row in sample_data.take(sample_size):\n",
    "                writer.writerow(row)\n",
    "        print(f\"Файл \\\"{file_path}\\\" с данными успешно создан.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при записи файла: {e}\")\n",
    "\n",
    "    return remaining_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определяем путь для сохранения `csv`-файла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"streaming-data.csv\"\n",
    "\n",
    "df = save_sample_to_csv(data=df, file_path=path, sample_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оцениваем, сколько строк в датасете осталось."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим датасет на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = df.randomSplit([0.8, 0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train dataset size: {train_df.count()}\")\n",
    "print(f\"Test  dataset size: {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понятно, что **идентификационный номер** автомобиля не оказывает влияния на цену. Использовать его в модели нет смысла.\n",
    "\n",
    "Остальные признаки сгруппируем по их типу:\n",
    "\n",
    "* **Категориальные** признаки не содержат большого количества категорий, закодируем их `one-hot`-кодировкой.\n",
    "* **Бинарные** признаки представлены значениями `true` / `false`, которые могут быть интерпретированы как единица и нуль. Поэтому, в кодировании не нуждаются.\n",
    "* **Количественные** признаки нужно нормализовать / стандартизировать, перед тем, как передавать их в модель.\n",
    "* Среди количественных признаков выделяется `mileage`, который по своим значениям больше напоминает бинарный. **Бинаризуем** его по порогу `100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"body_type\", \"wheel_system\"]\n",
    "binary_features = [\n",
    "    \"is_any_cert\", \"contains_Alloy Wheels\", \"contains_Backup Camera\",\n",
    "    \"contains_Bluetooth\", \"contains_Heated Seats\", \"contains_Sunroof/Moonroof\"\n",
    "]\n",
    "numeric_features = [\"daysonmarket\", \"horsepower\", \"maximum_seating\", \"age\"]\n",
    "binarizable_feature = \"mileage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим конвейер обработки данных, включающий модель линейной регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(categorical_features: list[str], numeric_features: list[str], \n",
    "                    binary_features: list[str], binarized_col: str, \n",
    "                    threshold: float, label_col: str, max_iter: int) -> Pipeline:\n",
    "    \n",
    "    # Формируем названия колонок для преобразованных признаков\n",
    "    indexed_categorical_features = [f\"{feature}_index\" for feature in categorical_features]\n",
    "    onehot_categorical_features = [f\"{feature}_ohe\" for feature in categorical_features]\n",
    "    \n",
    "    # Выполняем преобразования данных\n",
    "    string_indexer = StringIndexer(inputCols=categorical_features,\n",
    "                                   outputCols=indexed_categorical_features,\n",
    "                                   handleInvalid=\"keep\")\n",
    "    onehot_encoder = OneHotEncoder(inputCols=indexed_categorical_features,\n",
    "                                   outputCols=onehot_categorical_features,\n",
    "                                   dropLast=True,\n",
    "                                   handleInvalid=\"keep\")\n",
    "    vector_num_assembler = VectorAssembler(inputCols=numeric_features,\n",
    "                                           outputCol=\"numeric_vector\")\n",
    "    numeric_scaler = MinMaxScaler(inputCol=\"numeric_vector\",\n",
    "                                   outputCol=\"numeric_vector_scaled\")\n",
    "    binarizer = Binarizer(inputCol=binarized_col,\n",
    "                          outputCol=\"mileage_binary\",\n",
    "                          threshold=threshold)\n",
    "    vector_all_assembler = VectorAssembler(\n",
    "        inputCols=(onehot_categorical_features + binary_features +\n",
    "                   [\"numeric_vector_scaled\", \"mileage_binary\"]),\n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "\n",
    "    # Создаем модель линейной регрессии\n",
    "    linear_regression = LinearRegression(featuresCol=\"features\",\n",
    "                                         labelCol=label_col,\n",
    "                                         predictionCol=\"prediction\",\n",
    "                                         standardization=False,\n",
    "                                         maxIter=max_iter)\n",
    "\n",
    "    # Создаем конвейер\n",
    "    pipeline = Pipeline(stages=[\n",
    "        string_indexer, onehot_encoder, vector_num_assembler,\n",
    "        numeric_scaler, binarizer, vector_all_assembler,\n",
    "        linear_regression\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = create_pipeline(categorical_features=categorical_features,\n",
    "                           numeric_features=numeric_features,\n",
    "                           binary_features=binary_features,\n",
    "                           binarized_col=\"mileage\",\n",
    "                           threshold=100,\n",
    "                           label_col=\"price\",\n",
    "                           max_iter=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели\n",
    "\n",
    "Выполним **подбор гиперпараметров** модели линейной регрессии с помощью кросс-валидации на сетке.\n",
    "\n",
    "Создаем сетку параметров для кросс-валидации, получив объект `LinearRegression` из конвейера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(pipeline.getStages()[-1].regParam, [0.01, 0.1, 1.0]) \\\n",
    "    .addGrid(pipeline.getStages()[-1].elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем экземпляр `RegressionEvaluator` для оценки модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_evaluator = RegressionEvaluator(labelCol=\"price\",\n",
    "                                   predictionCol=\"prediction\",\n",
    "                                   metricName=\"rmse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем объект `CrossValidator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validator = CrossValidator(estimator=pipeline,\n",
    "                                 estimatorParamMaps=param_grid,\n",
    "                                 evaluator=cv_evaluator,\n",
    "                                 numFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель конвейера с использованием кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = cross_validator.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем параметры **лучшей** модели, определенной в ходе кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_params(cv_model: CrossValidatorModel) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Получает параметры лучшей модели из объекта CrossValidatorModel.\n",
    "\n",
    "    Args:\n",
    "        cv_model (CrossValidatorModel): Объект CrossValidatorModel, \n",
    "            содержащий лучшую модель.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Параметры лучшей модели.\n",
    "    \"\"\"\n",
    "    best_model = cv_model.bestModel\n",
    "    best_params = {\n",
    "        \"regParam\": best_model.stages[-1].getRegParam(),\n",
    "        \"elasticNetParam\": best_model.stages[-1].getElasticNetParam(),\n",
    "        \"maxIter\": best_model.stages[-1].getMaxIter()\n",
    "    }\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in get_best_model_params(cv_model=cv_model).items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Анализ процесса обучения\n",
    "\n",
    "Визуализируем изменение ошибки модели в ходе обучения и рассчитаем метрики на обучающем датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_summary(cv_model: DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Отображает графики зависимости значения ошибки от номера итерации на\n",
    "    обучающей выборке, а также значения метрик RMSE и R^2.\n",
    "\n",
    "    Args:\n",
    "        cv_model (DataFrame): Обученная модель с использованием кросс-валидации.\n",
    "    \"\"\"\n",
    "    # Получаем лучшую модель\n",
    "    best_model = cv_model.bestModel\n",
    "\n",
    "    # Получаем информацию о процессе обучения\n",
    "    training_summary = best_model.stages[-1].summary\n",
    "\n",
    "    # Получаем значения ошибки для каждой итерации\n",
    "    objective_history = training_summary.objectiveHistory\n",
    "\n",
    "    # Строим график зависимости значения ошибки от номера итерации\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.lineplot(x=range(len(objective_history)), \n",
    "                 y=objective_history, \n",
    "                 marker='o')\n",
    "    plt.xlabel('Итерация')\n",
    "    plt.ylabel('Ошибка')\n",
    "    plt.title(\"Зависимость значения функции ошибки от номера итерации\")\n",
    "\n",
    "    # Получаем значения метрик\n",
    "    rmse = training_summary.rootMeanSquaredError\n",
    "    r2 = training_summary.r2\n",
    "\n",
    "    # Добавляем значения метрик на график\n",
    "    plt.text(0.95, 0.95, f\"RMSE: {rmse:.2f}\\nR^2: {r2:.2f}\",\n",
    "             transform=plt.gca().transAxes, ha='right', va='top',\n",
    "             bbox=dict(facecolor='white', alpha=0.8), zorder=5)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_training_summary(cv_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Проверка обобщающей способности модели\n",
    "\n",
    "Выполним предсказания на тестовой выборке. \n",
    "\n",
    "Перегруппируем колонки датафрейма, переставив столбец с ценой автомобиля в конец, чтобы его значения было удобно сравнивать с предсказанными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем датасет предсказаний\n",
    "test_df_predictions = cv_model.transform(test_df)\n",
    "\n",
    "# Извлекаем список колонок, устанавливаем цену на последнее место\n",
    "right_columns_order = test_df_predictions.columns\n",
    "right_columns_order.remove(\"price\")\n",
    "right_columns_order.append(\"price\")\n",
    "\n",
    "# Изменяем последовательность колонок и выводим датафрейм\n",
    "test_df_predictions = test_df_predictions.select(*right_columns_order)\n",
    "test_df_predictions.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим функцию оценки модели: расчета метрик для некоторого датасета, как правило, тестового."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data: DataFrame, metric_name: str) -> float:\n",
    "    \"\"\"\n",
    "    Оценивает модель с использованием указанной метрики.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): DataFrame, содержащий предсказания и фактические метки.\n",
    "        metric_name (str): Название метрики для оценки (например, \"rmse\", \"r2\").\n",
    "\n",
    "    Returns:\n",
    "        float: Значение указанной метрики.\n",
    "    \"\"\"\n",
    "    evaluator = RegressionEvaluator(labelCol=\"price\", \n",
    "                                    predictionCol=\"prediction\", \n",
    "                                    metricName=metric_name)\n",
    "    metric_value = evaluator.evaluate(data)\n",
    "    return metric_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим модель на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_rmse = evaluate_model(test_df_predictions, \"rmse\")\n",
    "test_r2 = evaluate_model(test_df_predictions, \"r2\")\n",
    "\n",
    "print(f\"RMSE on test data: {test_rmse:.2f}\")\n",
    "print(f\"R^2 on test data: {test_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метрики весьма неплохие для линейной модели!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сохранение модели\n",
    "\n",
    "Зададим директорию студента в `HDFS`, в которой будет сохранена обученная модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_hdfs_folder = \"ivanov_directory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем имя пользователя\n",
    "user_name = os.getenv(\"USER\")\n",
    "\n",
    "# Путь модели в HDFS\n",
    "model_hdfs_path = f\"hdfs:///user/{user_name}/{student_hdfs_folder}/models/lr-model\"\n",
    "\n",
    "# Сохраняем модель конвейера в HDFS\n",
    "try:\n",
    "    cv_model.bestModel.save(model_hdfs_path)\n",
    "    print(f\"Модель успешно сохранена в \\\"{model_hdfs_path}\\\"\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при сохранении модели: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем завершать `Spark`-сессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
