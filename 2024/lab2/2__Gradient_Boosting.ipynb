{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лабораторная работа № 2 \n",
    "## Машинное обучение на больших данных с использованием фреймворка Apache Spark и библиотеки SparkML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Часть 2\n",
    "\n",
    "В данной части работы рассмотрены:\n",
    "* подготовка признаков для рашения задачи **градиентного бустинга** на деревьях решений;\n",
    "* создание и обучение модели градиентного бустинга;\n",
    "* оценка качества модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Запуск `Spark`-сессии\n",
    "\n",
    "Подключаем необходимые библиотеки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark import SparkConf\n",
    "from pyspark.ml.feature import VectorAssembler, StringIndexer, Binarizer, Bucketizer\n",
    "from pyspark.ml.functions import vector_to_array\n",
    "from pyspark.ml.classification import GBTClassifier, GBTClassificationModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, CrossValidatorModel, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "from pyspark.sql import Window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем объект конфигурации для `Apache Spark`, указав необходимые параметры."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_configuration() -> SparkConf:\n",
    "    \"\"\"\n",
    "    Создает и конфигурирует экземпляр SparkConf для приложения Spark.\n",
    "\n",
    "    Returns:\n",
    "        SparkConf: Настроенный экземпляр SparkConf.\n",
    "    \"\"\"\n",
    "    # Получаем имя пользователя\n",
    "    user_name = os.getenv(\"USER\")\n",
    "    \n",
    "    conf = SparkConf()\n",
    "    conf.setAppName(\"lab 2 Test\")\n",
    "    conf.setMaster(\"yarn\")\n",
    "    conf.set(\"spark.submit.deployMode\", \"client\")\n",
    "    conf.set(\"spark.executor.memory\", \"12g\")\n",
    "    conf.set(\"spark.executor.cores\", \"8\")\n",
    "    conf.set(\"spark.executor.instances\", \"2\")\n",
    "    conf.set(\"spark.driver.memory\", \"4g\")\n",
    "    conf.set(\"spark.driver.cores\", \"2\")\n",
    "    conf.set(\"spark.jars.packages\", \"org.apache.iceberg:iceberg-spark-runtime-3.5_2.12:1.6.0\")\n",
    "    conf.set(\"spark.sql.extensions\", \"org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog\", \"org.apache.iceberg.spark.SparkCatalog\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.type\", \"hadoop\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.warehouse\", f\"hdfs:///user/{user_name}/warehouse\")\n",
    "    conf.set(\"spark.sql.catalog.spark_catalog.io-impl\", \"org.apache.iceberg.hadoop.HadoopFileIO\")\n",
    "\n",
    "    return conf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём сам объект конфигурации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = create_spark_configuration()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаём и выводим на экран сессию `Apache Spark`. В процессе создания сессии происходит подключение к кластеру `Apache Hadoop`, что может занять некоторое время."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Загрузка датасета\n",
    "\n",
    "Укажем базу данных, которая была создана в первой лабораторной работе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_name = \"ivanov_database\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Установим созданную базу данных как текущую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.setCurrentDatabase(database_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаем таблицу с **предобработанным датасетом** и загрузим её в `Spark Dataframe`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.table(\"sobd_lab1_processed_table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем прочитанную таблицу на экран."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним описание столбцов и параметры датасета, проанализированные в первой лабораторной работе.\n",
    "\n",
    "| Название столбца          | Расшифровка |  Тип признака и его характеристики\n",
    "| ------------------------- | ------------- | ------------------ |\n",
    "| vin                       | Идентификационный номер автомобиля | категориальный, уникальный |\n",
    "| body_type                 | Тип кузова автомобиля (кабриолет, хэтчбек, седан и т.д.)  | категориальный, 10 категорий (одна неизвестная: NULL) |\n",
    "| daysonmarket              | Количество дней, прошедших с момента первого размещения автомобиля на сайте | количественный, непрерывный, интервал значений [0, 500] |\n",
    "| horsepower                | Мощность двигателя в лошадиных силах | количественный, непрерывный, интервал значений [0, 400] |\n",
    "| maximum_seating           | Максимальное количество посадочных мест | количественный, дискретный, интервал значений [2, 15] |\n",
    "| mileage                   | Величина пробега автомобиля | количественный, непрерывный, интервал значений [0, 200000], большинство значений < 100 |\n",
    "| price                     | Цена автомобиля | количественный, непрерывный, интервал значений [0, 60000] |\n",
    "| wheel_system              | Тип привода | категориальный, 5 категорий |\n",
    "| is_any_cert               | Является ли автомобиль сертифицированным (любым способом) | бинарный, true << false |\n",
    "| contains_Alloy Wheels     | Имеются ли в автомобиле легкосплавные диски | бинарный |\n",
    "| contains_Backup Camera    | Имеется ли в автомобиле резервная камера | бинарный |\n",
    "| contains_Bluetooth        | Имеется ли в автомобиле поддержка Bluetooth | бинарный |\n",
    "| contains_Heated Seats     | Имеется ли в автомобиле подогрев сидений | бинарный |\n",
    "| contains_Sunroof/Moonroof | Имеется ли в автомобиле люк | бинарный |\n",
    "| age                       | Количество лет, прошедших с года выпуска автомобиля до 2024 года | количественный, непрерывный, интервал значений [3, 43] |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вспомним схему данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислим количество строк в датафрейме."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Постановка задачи\n",
    "\n",
    "Для датасета, заданного представленными колонками, требуется построить модель **градиентного бустинга на деревьях решений** для оценки факта того, является ли автомобиль **сертифицированным**, по всем остальным признакам. \n",
    "\n",
    "Для оценки качества обучения следует использовать метрики `Precision` и `Recall`. Оценить максимально возможное значение **точности** при полноте не менее 60%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка и кодирование признаков\n",
    "\n",
    "Для корректной работы трансформеров и модели преобразуем столбец `mileage` к типу `DoubleType`, а столбец `is_any_cert` к типу `IntegerType`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn(\"mileage\", F.col(\"mileage\").cast(DoubleType()))\n",
    "df = df.withColumn(\"is_any_cert\", F.col(\"is_any_cert\").cast(IntegerType()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним **стратифицированное** разделение датасета на обучающую и тестовую выборки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratified_train_test_split(data: DataFrame, \n",
    "                                label_col: str,\n",
    "                                ratio: float) -> tuple[DataFrame, DataFrame]:\n",
    "    \"\"\"\n",
    "    Разделяет DataFrame на тренировочный и тестовый наборы с учетом стратификации.\n",
    "\n",
    "    Args:\n",
    "        data: Исходный DataFrame.\n",
    "        label_col: Название столбца с меткой.\n",
    "        ratio: Пропорция разделения данных.\n",
    "\n",
    "    Returns:\n",
    "        tuple[DataFrame, DataFrame]: Кортеж из тренировочного и тестового DataFrame.\n",
    "    \"\"\"\n",
    "    # Проверяем корректность доли разделения\n",
    "    assert (isinstance(ratio, float) and (0.0 <= ratio <= 1.0))\n",
    "    \n",
    "    # Формируем разделение для положительных и отрицательных объектов раздельно\n",
    "    train_df_pos, test_df_pos = (data\n",
    "                                 .filter(F.col(label_col) == 1)\n",
    "                                 .randomSplit([ratio, 1 - ratio]))\n",
    "    train_df_neg, test_df_neg = (data\n",
    "                                 .filter(F.col(label_col) == 0)\n",
    "                                 .randomSplit([ratio, 1 - ratio]))\n",
    "    \n",
    "    # Объединяем датафреймы\n",
    "    return (train_df_pos.union(train_df_neg),\n",
    "            test_df_pos.union(test_df_neg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = stratified_train_test_split(df, \"is_any_cert\", 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закешируем сформированные датафреймы и проверим их объем."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.cache()\n",
    "test_df = test_df.cache()\n",
    "\n",
    "print(f\"Train dataset size: {train_df.count()}\")\n",
    "print(f\"Test  dataset size: {test_df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы уже знаем из анализа датасета, если целевой переменной является `is_any_cert`, то датасет является **несбалансированным**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupBy(\"is_any_cert\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполним балансировку датасета с помощью `oversampling`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oversample(data: DataFrame, column: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Выполняет oversampling положительных классов в DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data: Исходный DataFrame.\n",
    "        column: Название столбца с меткой.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Датафрейм с выполненным oversampling.\n",
    "    \"\"\"\n",
    "    # Разделим датафрейм на положительные и отрицательные классы\n",
    "    pos = data.filter(F.col(column) == 1.0)\n",
    "    neg = data.filter(F.col(column) == 0.0)\n",
    "\n",
    "    # Получим количество записей в каждом классе\n",
    "    total_pos = pos.count()\n",
    "    total_neg = neg.count()\n",
    "\n",
    "    # Если количество положительных классов меньше отрицательных,\n",
    "    # выполним oversampling\n",
    "    if total_pos < total_neg:\n",
    "        # Вычислим количество необходимых дубликатов\n",
    "        num_duplicates = total_neg - total_pos\n",
    "\n",
    "        # Дублируем положительные записи\n",
    "        oversampled_pos = pos.withColumn(\n",
    "            \"dummy\",\n",
    "            F.explode(\n",
    "                F.array_repeat(F.lit(1),\n",
    "                               num_duplicates // total_pos + 1)\n",
    "            )\n",
    "        ).drop(\"dummy\")\n",
    "\n",
    "        # Объединим дублированные положительные записи с отрицательными\n",
    "        balanced_df = neg.union(oversampled_pos)\n",
    "    else:\n",
    "        balanced_df = data\n",
    "\n",
    "    return balanced_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "train_df = oversample(train_df, column=\"is_any_cert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим баланс классов в получившемся датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.groupBy(\"is_any_cert\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Понятно, что **идентификационный номер** автомобиля не оказывает влияния на сертификацию. Использовать его в модели нет смысла.\n",
    "\n",
    "Остальные признаки сгруппируем по их типу:\n",
    "\n",
    "* **Категориальные** признаки закодируем с помощью `label encoding`.\n",
    "* **Бинарные** признаки представлены значениями `true` / `false`, которые могут быть интерпретированы как единица и нуль. Поэтому, в кодировании не нуждаются.\n",
    "* **Количественные** признаки для древовидных моделей в кодировании не нуждаются.\n",
    "* Среди количественных признаков выделяется `mileage`, который по своим значениям больше напоминает бинарный. **Бинаризуем** его по порогу `100`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\"body_type\", \"wheel_system\"]\n",
    "binary_features = [\n",
    "    \"contains_Alloy Wheels\", \"contains_Backup Camera\", \"contains_Bluetooth\", \n",
    "    \"contains_Heated Seats\", \"contains_Sunroof/Moonroof\"\n",
    "]\n",
    "numeric_features = [\"daysonmarket\", \"horsepower\", \"price\", \"maximum_seating\", \"age\"]\n",
    "binarizable_feature = \"mileage\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим конвейер обработки данных, включающий модель градиентного бустинга на деревьях решений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pipeline(categorical_features: list[str], numeric_features: list[str], \n",
    "                    binary_features: list[str], binarized_col: str, \n",
    "                    threshold: float, label_col: str, max_iter: int) -> Pipeline:\n",
    "    \"\"\"\n",
    "    Создает конвейер для обработки данных и обучения модели градиентного бустинга.\n",
    "\n",
    "    Args:\n",
    "        categorical_features: Список категориальных признаков.\n",
    "        numeric_features: Список количественных признаков.\n",
    "        binary_features: Список бинарных признаков.\n",
    "        binarized_col: Название бинаризуемого признака.\n",
    "        threshold: Порог бинаризации.\n",
    "        label_col: Название столбца с меткой.\n",
    "        max_iter: Максимальное количество итераций для модели.\n",
    "\n",
    "    Returns:\n",
    "        Pipeline: Конвейер для обработки данных и обучения модели.\n",
    "    \"\"\"\n",
    "    # Формируем названия колонок для преобразованных признаков\n",
    "    indexed_categorical_features = [f\"{feature}_index\" for feature in categorical_features]\n",
    "    \n",
    "    # Выполняем преобразования данных\n",
    "    string_indexer = StringIndexer(inputCols=categorical_features,\n",
    "                                   outputCols=indexed_categorical_features,\n",
    "                                   handleInvalid=\"keep\")\n",
    "    binarizer = Binarizer(inputCol=binarized_col,\n",
    "                          outputCol=\"mileage_binary\",\n",
    "                          threshold=threshold)\n",
    "    vector_all_assembler = VectorAssembler(\n",
    "        inputCols=(indexed_categorical_features + binary_features +\n",
    "                   numeric_features + [\"mileage_binary\"]),\n",
    "        outputCol=\"features\"\n",
    "    )\n",
    "\n",
    "    # Создаем модель линейной регрессии\n",
    "    gbt_classifier = GBTClassifier(featuresCol=\"features\",\n",
    "                                   labelCol=label_col,\n",
    "                                   predictionCol=\"prediction\",\n",
    "                                   maxIter=max_iter)\n",
    "\n",
    "    # Создаем конвейер\n",
    "    pipeline = Pipeline(stages=[\n",
    "        string_indexer, binarizer, vector_all_assembler, gbt_classifier\n",
    "    ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = create_pipeline(categorical_features=categorical_features,\n",
    "                           numeric_features=numeric_features,\n",
    "                           binary_features=binary_features,\n",
    "                           binarized_col=\"mileage\",\n",
    "                           threshold=100,\n",
    "                           label_col=\"is_any_cert\",\n",
    "                           max_iter=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Обучение модели\n",
    "\n",
    "Выполним **подбор гиперпараметров** модели линейной регрессии с помощью кросс-валидации на сетке.\n",
    "\n",
    "Создаем сетку параметров для кросс-валидации, получив объект `GBTClassifier` из конвейера."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = ParamGridBuilder() \\\n",
    "#     .addGrid(pipeline.getStages()[-1].maxDepth, [3, 5, 7]) \\\n",
    "#     .addGrid(pipeline.getStages()[-1].stepSize, [0.1, 0.01, 0.001]) \\\n",
    "#     .build()\n",
    "\n",
    "# Подбор гиперпараметров, указанный выше, выполняется на кластере несколько часов :))\n",
    "# Для ознакомления можно использовать упрощенную процедуру, приведенную ниже\n",
    "param_grid = ParamGridBuilder() \\\n",
    "    .addGrid(pipeline.getStages()[-1].maxDepth, [5]) \\\n",
    "    .addGrid(pipeline.getStages()[-1].stepSize, [0.01]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем экземпляр `BinaryClassificationEvaluator` для оценки модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_evaluator = BinaryClassificationEvaluator(labelCol=\"is_any_cert\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создаем объект `CrossValidator`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validator = CrossValidator(estimator=pipeline,\n",
    "                                 estimatorParamMaps=param_grid,\n",
    "                                 evaluator=cv_evaluator,\n",
    "                                 numFolds=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучаем модель конвейера с использованием кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "cv_model = cross_validator.fit(train_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем параметры **лучшей** модели, определенной в ходе кросс-валидации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_model_params(cv_model: CrossValidatorModel) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Получает параметры лучшей модели из объекта CrossValidatorModel.\n",
    "\n",
    "    Args:\n",
    "        cv_model: Объект CrossValidatorModel, содержащий лучшую модель.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, float]: Параметры лучшей модели.\n",
    "    \"\"\"\n",
    "    best_model = cv_model.bestModel\n",
    "    best_params = {\n",
    "        \"maxDepth\": best_model.stages[-1].getMaxDepth(),\n",
    "        \"stepSize\": best_model.stages[-1].getStepSize(),\n",
    "        \"maxIter\": best_model.stages[-1].getMaxIter()\n",
    "    }\n",
    "    return best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in get_best_model_params(cv_model=cv_model).items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Анализ обученной модели\n",
    "\n",
    "Рассчитаем метрики на тестовом датасете."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получаем датасет предсказаний\n",
    "test_df_predictions = cv_model.transform(test_df)\n",
    "\n",
    "# Извлекаем список колонок, устанавливаем цену на последнее место\n",
    "right_columns_order = test_df_predictions.columns\n",
    "right_columns_order.remove(\"is_any_cert\")\n",
    "right_columns_order.append(\"is_any_cert\")\n",
    "\n",
    "# Изменяем последовательность колонок и выводим датафрейм\n",
    "test_df_predictions = test_df_predictions.select(*right_columns_order)\n",
    "test_df_predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data: DataFrame, \n",
    "                   label_col: str) -> dict[str, float]:\n",
    "    \"\"\"\n",
    "    Оценивает модель с использованием метрик точности, полноты и F1-score.\n",
    "\n",
    "    Args:\n",
    "        data: DataFrame, содержащий предсказания и фактические метки.\n",
    "        label_col: Название колонки с меткой.\n",
    "\n",
    "    Returns:\n",
    "        dict[str, float]: Словарь с метриками точности, полноты и F1-score.\n",
    "    \"\"\"\n",
    "    # Вычисляем TP, FP, FN\n",
    "    tp = data.filter((F.col(label_col) == 1) &\n",
    "                     (F.col(\"prediction\") == 1)).count()\n",
    "    fp = data.filter((F.col(label_col) == 0) &\n",
    "                     (F.col(\"prediction\") == 1)).count()\n",
    "    fn = data.filter((F.col(label_col) == 1) &\n",
    "                     (F.col(\"prediction\") == 0)).count()\n",
    "\n",
    "    # Вычисляем метрики\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = (2 * (precision * recall) / (precision + recall)\n",
    "        if (precision + recall) > 0 else 0)\n",
    "\n",
    "    # Возвращаем словарь с метриками\n",
    "    return {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1\": f1\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = evaluate_model(test_df_predictions, \"is_any_cert\")\n",
    "print(f\"Metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наблюдаем довольно низкую точность при высокой полноте. Попробуем подобрать `threshold`, чтобы максимизировать точность, но при этом удерживать полноту на заданном в постановке задачи уровне.\n",
    "Сначала рассчитаем `AUC ROC`, визуализируем `ROC` и `PR`-кривые и оценим ситуацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_auc_roc(model: GBTClassificationModel, \n",
    "                      test_data: DataFrame,\n",
    "                      label_col: str) -> float:\n",
    "    \"\"\"\n",
    "    Рассчитывает значение AUC ROC для модели.\n",
    "\n",
    "    Args:\n",
    "        model: Обученная модель классификации.\n",
    "        test_data: Тестовый набор данных.\n",
    "        label_col: Название столбца с меткой.\n",
    "\n",
    "    Returns:\n",
    "        float: Значение AUC ROC.\n",
    "    \"\"\"\n",
    "    # Получаем прогнозы модели\n",
    "    predictions = model.transform(test_data)\n",
    "\n",
    "    # Создаем \"оценщик\" бинарной классификации\n",
    "    evaluator = BinaryClassificationEvaluator(\n",
    "        rawPredictionCol=\"rawPrediction\",\n",
    "        labelCol=label_col\n",
    "    )\n",
    "\n",
    "    # Вычисляем AUC ROC\n",
    "    auc_roc = evaluator.evaluate(predictions)\n",
    "\n",
    "    return auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_metrics_df(predictions: DataFrame, label_col: str) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Подготавливает DataFrame для расчета FPR, TPR и Precision.\n",
    "\n",
    "    Args:\n",
    "        predictions: DataFrame с прогнозами модели.\n",
    "        label_col: Название столбца с меткой.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: DataFrame с рассчитанными столбцами FPR, TPR и Precision.\n",
    "    \"\"\"\n",
    "    # Формируем датафрейм, содержащий результат предсказания,\n",
    "    # вероятность предсказания и метку\n",
    "    metrics_df = (\n",
    "        predictions\n",
    "        .select(\n",
    "            vector_to_array(\n",
    "                F.col(\"probability\")\n",
    "            ).getItem(1).alias(\"probability\"),\n",
    "            \n",
    "            F.col(label_col).alias(\"label\"),\n",
    "            F.col(\"prediction\").cast(\"int\").alias(\"prediction\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Сортируем датафрейм по значениям вероятности\n",
    "    metrics_df = metrics_df.orderBy(\"probability\")\n",
    "\n",
    "    # Рассчитываем количество положительных и отрицательных классов\n",
    "    pos_count = metrics_df.filter(metrics_df.label == 1).count()\n",
    "    neg_count = metrics_df.filter(metrics_df.label == 0).count()\n",
    "\n",
    "    # Рассчитываем значения FPR и TPR\n",
    "    window = Window.partitionBy().orderBy(F.desc(\"probability\"))\n",
    "    metrics_df = (\n",
    "        metrics_df\n",
    "        .withColumn(\"FP_cum\", \n",
    "                    F.sum(F.when(\n",
    "                        F.col(\"label\") == 0, 1\n",
    "                    ).otherwise(0)).over(window))\n",
    "        .withColumn(\"TP_cum\", F.sum(F.col(\"label\")).over(window))\n",
    "        .withColumn(\"FPR\", F.col(\"FP_cum\") / neg_count)\n",
    "        .withColumn(\"TPR\", F.col(\"TP_cum\") / pos_count)\n",
    "        .withColumn(\"Precision\", \n",
    "                    F.col(\"TP_cum\") / (F.col(\"TP_cum\") + F.col(\"FP_cum\")))\n",
    "    )\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize_metrics_df(metrics_df: DataFrame, \n",
    "                         num_buckets: int = 1000) -> DataFrame:\n",
    "    \"\"\"\n",
    "    Применяет Bucketizer к DataFrame для уменьшения объёма данных, \n",
    "    возвращаемых на драйвер.\n",
    "\n",
    "    Args:\n",
    "        metrics_df: DataFrame с рассчитанными столбцами FPR, TPR и Precision.\n",
    "        num_buckets: Количество бакетов.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Бакетизированный Dataframe.\n",
    "    \"\"\"\n",
    "    # Определяем границы бакетов\n",
    "    bucketizer = Bucketizer(\n",
    "        splits=list(np.linspace(0, 1, num_buckets + 1)),\n",
    "        inputCol=\"probability\",\n",
    "        outputCol=\"bucket\"\n",
    "    )\n",
    "\n",
    "    # Применяем Bucketizer\n",
    "    metrics_df = bucketizer.setHandleInvalid(\"error\").transform(metrics_df)\n",
    "\n",
    "    # Формируем одну точку из каждого бакета\n",
    "    metrics_df = metrics_df.groupBy(\"bucket\").agg(\n",
    "        F.avg(F.col(\"probability\")).alias(\"probability\"),\n",
    "        F.avg(F.col(\"FPR\")).alias(\"FPR\"),\n",
    "        F.avg(F.col(\"TPR\")).alias(\"TPR\"),\n",
    "        F.avg(F.col(\"Precision\")).alias(\"Precision\")\n",
    "    )\n",
    "\n",
    "    return metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(model: GBTClassificationModel, \n",
    "                      test_data: DataFrame,\n",
    "                      label_col: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Рассчитывает значения FPR, TPR и Precision для построения ROC и PR-кривых.\n",
    "\n",
    "    Args:\n",
    "        model: Обученная модель классификации.\n",
    "        test_data: Тестовый набор данных.\n",
    "        label_col: Название столбца с меткой.\n",
    "\n",
    "    Returns:\n",
    "        tuple[float, pd.DataFrame]: Кортеж из значения AUC ROC и DataFrame \n",
    "                                    со значениями FPR, TPR и Precision.\n",
    "    \"\"\"\n",
    "    # Получаем прогнозы модели\n",
    "    predictions = model.transform(test_data)\n",
    "\n",
    "    # Подготавливаем DataFrame для расчета FPR, TPR и Precision\n",
    "    metrics_df = prepare_metrics_df(predictions, label_col)\n",
    "\n",
    "    # Применяем Bucketizer к DataFrame\n",
    "    metrics_df = bucketize_metrics_df(metrics_df)\n",
    "\n",
    "    return metrics_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_pr_curves(pd_data: pd.DataFrame, \n",
    "                       auc_roc: float) -> None:\n",
    "    \"\"\"\n",
    "    Визуализирует ROC и PR-кривые, добавляет на график AUC ROC.\n",
    "\n",
    "    Args:\n",
    "        pd_data: Pandas DataFrame, содержащий столбцы \n",
    "            \"FPR\", \"TPR\", \"Precision\".\n",
    "        auc_roc: Значение AUC-ROC.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "    # Построение ROC-кривой\n",
    "    sns.lineplot(x=\"FPR\", y=\"TPR\", data=pd_data, ax=axes[0])\n",
    "    sns.lineplot(x=[0, 1], y=[0, 1], \n",
    "                 color=\"gray\", linestyle=\"--\", ax=axes[0])\n",
    "    axes[0].set_xlabel(\"False Positive Rate (FPR)\")\n",
    "    axes[0].set_ylabel(\"True Positive Rate (TPR)\")\n",
    "    axes[0].set_title(\"ROC Curve\")\n",
    "    axes[0].grid()\n",
    "\n",
    "    # Добавляем значение AUC-ROC в правом нижнем углу графика\n",
    "    axes[0].text(0.94, 0.06, f'AUC-ROC: {auc_roc:.2f}', \n",
    "                 transform=axes[0].transAxes,\n",
    "                 fontsize=12, verticalalignment='bottom', \n",
    "                 horizontalalignment='right',\n",
    "                 bbox=dict(facecolor='white', \n",
    "                           alpha=0.8), zorder=5)\n",
    "\n",
    "    # Построение PR-кривой\n",
    "    sns.lineplot(x=\"TPR\", y=\"Precision\", \n",
    "                 data=pd_data, ax=axes[1])\n",
    "    axes[1].set_xlabel(\"Recall\")\n",
    "    axes[1].set_ylabel(\"Precision\")\n",
    "    axes[1].set_title(\"PR Curve\")\n",
    "    axes[1].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Рассчитываем AUC ROC\n",
    "auc_roc = calculate_auc_roc(model=cv_model,\n",
    "                            test_data=test_df,\n",
    "                            label_col=\"is_any_cert\")\n",
    "pd_dataframe = calculate_metrics(model=cv_model,\n",
    "                                 test_data=test_df,\n",
    "                                 label_col=\"is_any_cert\")\n",
    "plot_roc_pr_curves(pd_dataframe, auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим вероятность -- границу разделения, при которой `Recall` не меньше 60%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_probability = pd_dataframe[pd_dataframe['TPR'] >= 0.60]['probability'].max()\n",
    "print(f\"Вероятность -- граница разделения, при которой TPR не меньше 60%: {threshold_probability:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассчитаем метрики на тестовом датасете повторно, с учетом вычисленного `threshold` для вероятности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model.bestModel.stages[-1].setThresholds([1 - threshold_probability, \n",
    "                                             threshold_probability])\n",
    "test_df_predictions = cv_model.transform(test_df)\n",
    "metrics = evaluate_model(test_df_predictions, \"is_any_cert\")\n",
    "print(f\"Metrics: {metrics}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обученная модель обладает не очень хорошим качеством. Для дальнейшего улучшения качества предсказания можно подобрать другую модель, сформировать другие признаки, добавить к модели дополнительные данные и т.д."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не забываем завершать `Spark`-сессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyspark-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
